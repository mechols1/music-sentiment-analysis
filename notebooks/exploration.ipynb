{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pylast\n",
    "import os, multiprocessing as mp\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from music_sentiment.lastfm_api import get_lastfm_network, get_song_tags\n",
    "from music_sentiment.tag_utils import process_tag_weights\n",
    "\n",
    "#load the environment variables from the .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned dataset\n",
    "\n",
    "df = pd.read_csv(\"../data/cleaned/muse_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a cache directory if it doesn't exist\n",
    "cache_dir = Path(\"../data/cache\")\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "cache_file = cache_dir / \"lastfm_song_tags_cache.json\"\n",
    "\n",
    "# Initialize or load cache\n",
    "def load_cache():\n",
    "    if cache_file.exists():\n",
    "        with open(cache_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "# Modified function to use cache\n",
    "def get_song_tags_cached(network, artist, track, limit=20, cache=None):\n",
    "    \"\"\"Get song tags with caching\"\"\"\n",
    "    # Create a unique key for this artist-track pair\n",
    "    cache_key = f\"{artist.lower().strip()}|{track.lower().strip()}\"\n",
    "    \n",
    "    # Check if we have this in our cache\n",
    "    if cache and cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Not in cache, fetch from API\n",
    "    try:\n",
    "        tags = get_song_tags(network, artist, track, limit)\n",
    "        \n",
    "        # Store in cache\n",
    "        if cache is not None:\n",
    "            cache[cache_key] = tags\n",
    "            # Periodically save cache to disk (e.g., every 10 new entries)\n",
    "            if len(cache) % 10 == 0:\n",
    "                save_cache(cache)\n",
    "                \n",
    "        return tags\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tags for {artist} - {track}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Worker function for parallel processing\n",
    "def process_song(args):\n",
    "    idx, row, network, cache = args\n",
    "    artist, track = row['artist'], row['track']\n",
    "    \n",
    "    # Add rate limiting to avoid hitting API limits\n",
    "    # Sleep a small random amount to distribute requests\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    # Get tags using cache when available\n",
    "    song_tags = get_song_tags_cached(network, artist, track, cache=cache)\n",
    "    \n",
    "    # Process tags into weighted text string using your updated function\n",
    "    tag_text = process_tag_weights(song_tags)\n",
    "    \n",
    "    return idx, song_tags, tag_text\n",
    "\n",
    "# Main processing function with parallel execution\n",
    "def fetch_tags_parallel(df_sample, max_workers=4):\n",
    "    # Load cache\n",
    "    cache = load_cache()\n",
    "    \n",
    "    network = get_lastfm_network()\n",
    "    total_songs = len(df_sample)\n",
    "    \n",
    "    print(f\"Fetching tags for {total_songs} songs using {max_workers} workers...\")\n",
    "    \n",
    "    # Prepare data structure to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Create a list of tasks\n",
    "    tasks = [(idx, row, network, cache) for idx, row in df_sample.iterrows()]\n",
    "    \n",
    "    # Use ThreadPoolExecutor for I/O bound tasks like API calls\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks and process results as they complete\n",
    "        futures = {executor.submit(process_song, task): task[0] for task in tasks}\n",
    "        \n",
    "        # Use tqdm for a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            idx, song_tags, tag_text = future.result()\n",
    "            results[idx] = (song_tags, tag_text)\n",
    "    \n",
    "    # Save the final cache\n",
    "    save_cache(cache)\n",
    "    \n",
    "    # Extract results in the same order as the input DataFrame\n",
    "    tags_with_weights = []\n",
    "    tags_text_list = []\n",
    "    \n",
    "    for idx in df_sample.index:\n",
    "        if idx in results:\n",
    "            tags_with_weights.append(results[idx][0])\n",
    "            tags_text_list.append(results[idx][1])\n",
    "        else:\n",
    "            # Handle missing results (e.g., if there was an error)\n",
    "            tags_with_weights.append([])\n",
    "            tags_text_list.append(\"\")  # Empty string instead of empty dict\n",
    "    \n",
    "    return tags_with_weights, tags_text_list\n",
    "\n",
    "# Main execution code\n",
    "sample_size = 2000\n",
    "df_sample = df.sample(sample_size, random_state=42)\n",
    "\n",
    "# Fetch tags in parallel\n",
    "tags_with_weights, tags_text_list = fetch_tags_parallel(df_sample, max_workers=4)\n",
    "\n",
    "# Add the tags to the DataFrame\n",
    "df_sample['tags_with_weights'] = tags_with_weights\n",
    "df_sample['tag_text'] = tags_text_list\n",
    "\n",
    "# Ensure no NaN values in tag_text by replacing any potential empty values with empty strings\n",
    "df_sample['tag_text'] = df_sample['tag_text'].fillna(\"\")\n",
    "\n",
    "# Save the DataFrame with tags to a CSV file\n",
    "df_sample.to_csv(\"../data/cleaned/muse_with_tags_valence.csv\", index=False)\n",
    "\n",
    "print(f\"Processing complete. Data saved to ../data/cleaned/muse_with_tags_valence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.83      0.34      0.48       207\n",
      "           2       0.64      0.87      0.74       337\n",
      "           3       0.50      0.11      0.19        44\n",
      "\n",
      "    accuracy                           0.62       600\n",
      "   macro avg       0.49      0.33      0.35       600\n",
      "weighted avg       0.68      0.62      0.59       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Load the dataset with tags\n",
    "df_sample = pd.read_csv(\"../data/cleaned/muse_with_tags_valence.csv\")\n",
    "\n",
    "# ComplementNB works with sparse matrices directly\n",
    "\n",
    "# Your existing code for feature extraction\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_df=0.7)\n",
    "df_sample_filtered = df_sample.dropna(subset=['tag_text'])\n",
    "X = vectorizer.fit_transform(df_sample_filtered['tag_text'])\n",
    "\n",
    "# Bin the valence scores into discrete categories\n",
    "bins = [0, 2.5, 5, 7.5, 10]  # You can adjust these bins\n",
    "labels = [0, 1, 2, 3]    # Numeric labels for the bins\n",
    "df_sample['valence_binned'] = pd.cut(df_sample['valence_tags'], bins=bins, labels=labels)\n",
    "\n",
    "# Use the binned values as target\n",
    "y = df_sample['valence_binned']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Use ComplementNB which works well with sparse features\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)  # No need for .toarray()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy: 0.7357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.23      0.17        44\n",
      "           1       0.95      0.54      0.69       485\n",
      "           2       0.71      0.94      0.81       777\n",
      "           3       1.00      0.30      0.46        94\n",
      "\n",
      "    accuracy                           0.74      1400\n",
      "   macro avg       0.70      0.50      0.53      1400\n",
      "weighted avg       0.80      0.74      0.72      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# evaluate model on the training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# print evaluation metrics with the same format as the test set\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"Training Data Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "dump(model, '../models/valence_classifier.joblib')\n",
    "# Save the vectorizer\n",
    "dump(vectorizer, '../models/tfidf_vectorizer.joblib')\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a new approach, using the warriner list to map Last.fm tags to words tied with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your exploration.ipynb or a new notebook\n",
    "\n",
    "# Load the cleaned Warriner dataset\n",
    "warriner_df = pd.read_csv('../data/cleaned/warriner_clean.csv')\n",
    "\n",
    "# Create a dictionary for faster lookups\n",
    "warriner_dict = dict(zip(warriner_df['word'], zip(\n",
    "    warriner_df['valence_score'], \n",
    "    warriner_df['arousal_score'], \n",
    "    warriner_df['dominance_score']\n",
    ")))\n",
    "\n",
    "# Function to extract Warriner features from tags\n",
    "def extract_warriner_features(tag_text, warriner_df):\n",
    "    # Split the tag text into individual words\n",
    "    words = set(tag_text.lower().split())\n",
    "    \n",
    "    # Initialize feature dictionary\n",
    "    features = {\n",
    "        'warriner_valence_mean': 0.0,\n",
    "        'warriner_arousal_mean': 0.0,\n",
    "        'warriner_dominance_mean': 0.0,\n",
    "        'warriner_coverage': 0.0\n",
    "    }\n",
    "    \n",
    "    # Match words with the Warriner lexicon\n",
    "    matched_words = []\n",
    "    for word in words:\n",
    "        if word in warriner_df.index:\n",
    "            matched_words.append(word)\n",
    "    \n",
    "    # Calculate coverage\n",
    "    if len(words) > 0:\n",
    "        features['warriner_coverage'] = len(matched_words) / len(words)\n",
    "    \n",
    "    # Calculate emotion scores\n",
    "    if matched_words:\n",
    "        valence_scores = [warriner_df.loc[word, 'V.Mean.Sum'] for word in matched_words]\n",
    "        arousal_scores = [warriner_df.loc[word, 'A.Mean.Sum'] for word in matched_words]\n",
    "        dominance_scores = [warriner_df.loc[word, 'D.Mean.Sum'] for word in matched_words]\n",
    "        \n",
    "        features['warriner_valence_mean'] = sum(valence_scores) / len(valence_scores)\n",
    "        features['warriner_arousal_mean'] = sum(arousal_scores) / len(arousal_scores)\n",
    "        features['warriner_dominance_mean'] = sum(dominance_scores) / len(dominance_scores)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.72      0.96      0.82       381\n",
      "         sad       0.82      0.34      0.48       219\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.77      0.65      0.65       600\n",
      "weighted avg       0.76      0.73      0.70       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "# Load Warriner wordlist\n",
    "warriner_df = pd.read_csv('../data/cleaned/warriner_clean.csv', index_col='word')\n",
    "\n",
    "# Apply Warriner features to your dataset\n",
    "for idx, row in df_sample.iterrows():\n",
    "    if pd.notna(row['tag_text']):\n",
    "        warriner_features = extract_warriner_features(row['tag_text'], warriner_df)\n",
    "        for feature, value in warriner_features.items():\n",
    "            df_sample.at[idx, feature] = value\n",
    "\n",
    "# Get your numeric features and scale them\n",
    "warriner_cols = ['warriner_valence_mean', 'warriner_arousal_mean', 'warriner_dominance_mean', 'warriner_coverage']\n",
    "X_warriner = df_sample[warriner_cols].fillna(0).values\n",
    "scaler = StandardScaler()\n",
    "X_warriner_scaled = scaler.fit_transform(X_warriner)\n",
    "\n",
    "# Get your text features\n",
    "X_tfidf = vectorizer.fit_transform(df_sample['tag_text'].fillna(''))\n",
    "\n",
    "# Combine features\n",
    "X_combined = hstack([X_tfidf, X_warriner_scaled])\n",
    "\n",
    "# Split for training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, df_sample['emotion'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Train your model\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
