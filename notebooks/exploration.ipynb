{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pylast\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from music_sentiment.lastfm_api import get_lastfm_network, get_song_tags\n",
    "from music_sentiment.tag_utils import process_tag_weights\n",
    "\n",
    "#load the environment variables from the .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned dataset\n",
    "\n",
    "df = pd.read_csv(\"../data/cleaned/muse_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network for last.fm\n",
    "network = get_lastfm_network()\n",
    "\n",
    "# start with a smaller subset of the dataset\n",
    "sample_size = 2000\n",
    "df_sample = df.sample(sample_size, random_state=42)\n",
    "\n",
    "# Fetch tags for each song in the sample\n",
    "print(\"Fetching tags for each song in the sample...\")\n",
    "tags_text_list = []\n",
    "tags_with_weights = []\n",
    "\n",
    "for idx, row in df_sample.iterrows():\n",
    "    print(f\"Processing {idx+1}/{len(df_sample)}: {row['artist']} - {row['track']}\")\n",
    "    song_tags = get_song_tags(network, row['artist'], row['track'])\n",
    "    \n",
    "    # store tag data with weight for each tag\n",
    "    tags_with_weights.append(song_tags)\n",
    "    tags_text_list.append(process_tag_weights(song_tags))\n",
    "    \n",
    "    \n",
    "# Add the tags to the DataFrame\n",
    "df_sample['tags_with_weights'] = tags_with_weights\n",
    "df_sample['tag_text'] = tags_text_list\n",
    "# Save the DataFrame with tags to a CSV file\n",
    "df_sample.to_csv(\"../data/cleaned/muse_with_tags_valence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.08      0.06        12\n",
      "           1       0.71      0.47      0.57       207\n",
      "           2       0.67      0.84      0.74       337\n",
      "           3       0.41      0.16      0.23        44\n",
      "\n",
      "    accuracy                           0.65       600\n",
      "   macro avg       0.46      0.39      0.40       600\n",
      "weighted avg       0.65      0.65      0.63       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Load the dataset with tags\n",
    "df_sample = pd.read_csv(\"../data/cleaned/muse_with_tags_valence.csv\")\n",
    "\n",
    "# ComplementNB works with sparse matrices directly\n",
    "\n",
    "# Your existing code for feature extraction\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_df=0.7)\n",
    "X = vectorizer.fit_transform(df_sample['tag_text'])\n",
    "\n",
    "# Bin the valence scores into discrete categories\n",
    "bins = [0, 2.5, 5, 7.5, 10]  # You can adjust these bins\n",
    "labels = [0, 1, 2, 3]    # Numeric labels for the bins\n",
    "df_sample['valence_binned'] = pd.cut(df_sample['valence_tags'], bins=bins, labels=labels)\n",
    "\n",
    "# Use the binned values as target\n",
    "y = df_sample['valence_binned']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Use ComplementNB which works well with sparse features\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)  # No need for .toarray()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy: 0.7914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.30      0.37        44\n",
      "           1       0.89      0.66      0.76       485\n",
      "           2       0.76      0.95      0.84       777\n",
      "           3       0.92      0.38      0.54        94\n",
      "\n",
      "    accuracy                           0.79      1400\n",
      "   macro avg       0.77      0.57      0.63      1400\n",
      "weighted avg       0.81      0.79      0.78      1400\n",
      "\n",
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# evaluate model on the training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# print evaluation metrics with the same format as the test set\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f\"Training Data Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "dump(model, '../models/valence_classifier.joblib')\n",
    "# Save the vectorizer\n",
    "dump(vectorizer, '../models/tfidf_vectorizer.joblib')\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a new approach, using the warriner list to map Last.fm tags to words tied with emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your exploration.ipynb or a new notebook\n",
    "\n",
    "# Load the cleaned Warriner dataset\n",
    "warriner_df = pd.read_csv('../data/cleaned/warriner_clean.csv')\n",
    "\n",
    "# Create a dictionary for faster lookups\n",
    "warriner_dict = dict(zip(warriner_df['word'], zip(\n",
    "    warriner_df['valence_score'], \n",
    "    warriner_df['arousal_score'], \n",
    "    warriner_df['dominance_score']\n",
    ")))\n",
    "\n",
    "# Function to extract Warriner features from tags\n",
    "def extract_warriner_features(tag_text, warriner_df):\n",
    "    # Split the tag text into individual words\n",
    "    words = set(tag_text.lower().split())\n",
    "    \n",
    "    # Initialize feature dictionary\n",
    "    features = {\n",
    "        'warriner_valence_mean': 0.0,\n",
    "        'warriner_arousal_mean': 0.0,\n",
    "        'warriner_dominance_mean': 0.0,\n",
    "        'warriner_coverage': 0.0\n",
    "    }\n",
    "    \n",
    "    # Match words with the Warriner lexicon\n",
    "    matched_words = []\n",
    "    for word in words:\n",
    "        if word in warriner_df.index:\n",
    "            matched_words.append(word)\n",
    "    \n",
    "    # Calculate coverage\n",
    "    if len(words) > 0:\n",
    "        features['warriner_coverage'] = len(matched_words) / len(words)\n",
    "    \n",
    "    # Calculate emotion scores\n",
    "    if matched_words:\n",
    "        valence_scores = [warriner_df.loc[word, 'V.Mean.Sum'] for word in matched_words]\n",
    "        arousal_scores = [warriner_df.loc[word, 'A.Mean.Sum'] for word in matched_words]\n",
    "        dominance_scores = [warriner_df.loc[word, 'D.Mean.Sum'] for word in matched_words]\n",
    "        \n",
    "        features['warriner_valence_mean'] = sum(valence_scores) / len(valence_scores)\n",
    "        features['warriner_arousal_mean'] = sum(arousal_scores) / len(arousal_scores)\n",
    "        features['warriner_dominance_mean'] = sum(dominance_scores) / len(dominance_scores)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       happy       0.79      0.69      0.74        39\n",
      "         sad       0.54      0.67      0.60        21\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.67      0.68      0.67        60\n",
      "weighted avg       0.70      0.68      0.69        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "# Load Warriner wordlist\n",
    "warriner_df = pd.read_csv('../data/cleaned/warriner_clean.csv', index_col='word')\n",
    "\n",
    "# Apply Warriner features to your dataset\n",
    "for idx, row in df_sample.iterrows():\n",
    "    if pd.notna(row['tag_text']):\n",
    "        warriner_features = extract_warriner_features(row['tag_text'], warriner_df)\n",
    "        for feature, value in warriner_features.items():\n",
    "            df_sample.at[idx, feature] = value\n",
    "\n",
    "# Get your numeric features and scale them\n",
    "warriner_cols = ['warriner_valence_mean', 'warriner_arousal_mean', 'warriner_dominance_mean', 'warriner_coverage']\n",
    "X_warriner = df_sample[warriner_cols].fillna(0).values\n",
    "scaler = StandardScaler()\n",
    "X_warriner_scaled = scaler.fit_transform(X_warriner)\n",
    "\n",
    "# Get your text features\n",
    "X_tfidf = vectorizer.fit_transform(df_sample['tag_text'].fillna(''))\n",
    "\n",
    "# Combine features\n",
    "X_combined = hstack([X_tfidf, X_warriner_scaled])\n",
    "\n",
    "# Split for training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, df_sample['emotion'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Train your model\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
